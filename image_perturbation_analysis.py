# -*- coding: utf-8 -*-
"""Image perturbation analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j6Mb2_GGgJny_kK3n3rvPG5HA_ZBuXDX
"""

pip install tensorflow numpy matplotlib

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt

# Step 1: Load and Preprocess the MNIST Dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Use only 2000 samples from each dataset
x_train = x_train[:2000]
y_train = y_train[:2000]
x_test = x_test[:2000]
y_test = y_test[:2000]

# Reshape and normalize the dataset to fit MobileNet input requirements
x_train = np.stack((x_train,) * 3, axis=-1)  # Convert grayscale to RGB by stacking
x_test = np.stack((x_test,) * 3, axis=-1)    # Convert grayscale to RGB by stacking
x_train = tf.image.resize(x_train, (96, 96))  # Resize images to 96x96
x_test = tf.image.resize(x_test, (96, 96))    # Resize images to 96x96
x_train = preprocess_input(x_train)           # Preprocess input for MobileNetV2
x_test = preprocess_input(x_test)             # Preprocess input for MobileNetV2

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Step 2: Apply Gaussian Noise
def add_gaussian_noise(images, mean=0.0, std=0.1):
    noise = np.random.normal(mean, std, images.shape)
    noisy_images = images + noise
    noisy_images = np.clip(noisy_images, -1, 1)  # Ensure pixel values are in the [-1, 1] range
    return noisy_images

x_train_noisy = add_gaussian_noise(x_train)
x_test_noisy = add_gaussian_noise(x_test)

# Combine clean and noisy data for training
x_combined_train = np.concatenate((x_train, x_train_noisy), axis=0)
y_combined_train = np.concatenate((y_train, y_train), axis=0)

# Display some noisy images
plt.figure(figsize=(10, 2))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(tf.squeeze((x_train_noisy[i] + 1) / 2))  # Adjust for display
    plt.axis('off')
plt.show()

# Step 3: Load Pre-trained MobileNetV2 Model
base_model = MobileNetV2(weights='imagenet', input_shape=(96, 96, 3), include_top=False)
base_model.trainable = False

# Add a global spatial average pooling layer and a fully-connected layer
mobilenet_model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(10, activation='softmax')  # Output layer for 10 classes
])

# Compile the model
mobilenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 4: Data Augmentation Setup
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1
)

# Fit the model using augmented data on combined dataset
mobilenet_model.fit(
    datagen.flow(x_combined_train, y_combined_train, batch_size=32),
    epochs=5,
    validation_data=(x_test, y_test)
)

# Evaluate model performance on the noisy test set
test_loss, test_acc = mobilenet_model.evaluate(x_test_noisy, y_test)
print(f'Test Accuracy on Noisy Images: {test_acc:.4f}')

# Step 5: Evaluate the Model on Clean Test Data
clean_loss, clean_acc = mobilenet_model.evaluate(x_test, y_test, verbose=0)
print(f'Clean Test Accuracy: {clean_acc:.4f}')

# Step 6: Evaluate the Model on Noisy Test Data (already done earlier)
noisy_loss, noisy_acc = mobilenet_model.evaluate(x_test_noisy, y_test, verbose=0)
print(f'Noisy Test Accuracy: {noisy_acc:.4f}')

# Accuracy Drop Calculation
accuracy_drop = clean_acc - noisy_acc
print(f'Accuracy Drop: {accuracy_drop:.4f}')

# Step 7: Calculate Label Flipping Rate and Confidence Score Degradation

# Get model predictions on clean and noisy data
clean_predictions = mobilenet_model.predict(x_test, verbose=0)
noisy_predictions = mobilenet_model.predict(x_test_noisy, verbose=0)

# Convert predictions to class labels
clean_labels = np.argmax(clean_predictions, axis=1)
noisy_labels = np.argmax(noisy_predictions, axis=1)

# Calculate Label Flipping Rate
label_flips = np.sum(clean_labels != noisy_labels)
label_flipping_rate = label_flips / len(clean_labels)
print(f'Label Flipping Rate: {label_flipping_rate:.4f}')

# Calculate Confidence Score Degradation
clean_confidences = np.max(clean_predictions, axis=1)
noisy_confidences = np.max(noisy_predictions, axis=1)

confidence_score_degradation = np.mean(clean_confidences - noisy_confidences)
print(f'Confidence Score Degradation: {confidence_score_degradation:.4f}')

